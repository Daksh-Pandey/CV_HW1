{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Calibration Error computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools tqdm tidecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from tidecv import TIDE, datasets\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Set\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Expected Calibration Error (ECE) \n",
    "\n",
    "ECE is a metric to evaluate the calibration of a model. It is defined as the expected value of the absolute difference between the accuracy and the confidence of the model. The confidence of the model is the probability assigned to the predicted class. The accuracy is 1 if the prediction is correct and 0 otherwise. The ECE is computed by dividing the confidence interval [0, 1] into M equally spaced bins and computing the weighted average of the absolute difference between the accuracy and the confidence in each bin. The weights are the proportion of samples in each bin. The ECE is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "ECE = \\sum_{m=1}^{M} \\frac{B_m}{N} \\left| \\text{acc}(B_m) - \\text{conf}(B_m) \\right|\n",
    "\\end{equation}\n",
    "\n",
    "where $B_m$ is the set of samples in bin $m$, $N$ is the total number of samples, $\\text{acc}(B_m)$ is the accuracy of the model in bin $m$, and $\\text{conf}(B_m)$ is the confidence of the model in bin $m$. The accuracy and confidence in bin $m$ are defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{acc}(B_m) = \\frac{1}{|B_m|} \\sum_{i \\in B_m} \\mathbb{1} \\left( y_i = \\hat{y}_i \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{conf}(B_m) = \\frac{1}{|B_m|} \\sum_{i \\in B_m} p_i\n",
    "\\end{equation}\n",
    "\n",
    "where $y_i$ is the true label of sample $i$, $\\hat{y}_i$ is the predicted label of sample $i$, $p_i$ is the confidence of the model for sample $i$, and $\\mathbb{1}(\\cdot)$ is the indicator function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Code\n",
    "\n",
    "The following section contains some starter code to help you prepare the data using the COCO API. You can use this code to preprocess the data, or you can write your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Detection:\n",
    "    bbox: np.ndarray  # [x1, y1, x2, y2]\n",
    "    class_id: int\n",
    "    confidence: float\n",
    "\n",
    "@dataclass\n",
    "class GroundTruth:\n",
    "    bbox: np.ndarray  # [x1, y1, x2, y2]\n",
    "    class_id: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_corners(bbox):\n",
    "    \"\"\"Convert COCO bbox [x,y,w,h] to corners format [x1,y1,x2,y2]\"\"\"\n",
    "    return np.array([\n",
    "        bbox[0],\n",
    "        bbox[1],\n",
    "        bbox[0] + bbox[2],\n",
    "        bbox[1] + bbox[3]\n",
    "    ])\n",
    "\n",
    "def get_image_annotations(coco_gt, coco_dt, img_id, max_dets=100):\n",
    "    \"\"\"Get list of ground truth and detection annotations across all images\"\"\"\n",
    "    gt_ids = coco_gt.getAnnIds(imgIds=img_id)\n",
    "    gt_anns = coco_gt.loadAnns(gt_ids)\n",
    "    gts = [\n",
    "        GroundTruth(\n",
    "            bbox=coco_to_corners(ann['bbox']),\n",
    "            class_id=ann['category_id']\n",
    "        )\n",
    "        for ann in gt_anns\n",
    "    ]\n",
    "\n",
    "    # Get detections\n",
    "    dt_ids = coco_dt.getAnnIds(imgIds=img_id)\n",
    "    dt_anns = coco_dt.loadAnns(dt_ids)\n",
    "    if max_dets is not None:\n",
    "        dt_anns = sorted(dt_anns, key=lambda x: x['score'], reverse=True)[:max_dets]\n",
    "    dets = [\n",
    "        Detection(\n",
    "            bbox=coco_to_corners(ann['bbox']),\n",
    "            class_id=ann['category_id'],\n",
    "            confidence=ann['score']\n",
    "        )\n",
    "        for ann in dt_anns\n",
    "    ]\n",
    "\n",
    "    return gts, dets\n",
    "\n",
    "def prepare_inputs(coco_gt, coco_dt, max_dets=100):\n",
    "    \"\"\"Convert COCO format to TIDE format for all images\"\"\"\n",
    "    all_gts = []\n",
    "    all_dets = []\n",
    "    \n",
    "    for img_id in tqdm(coco_gt.getImgIds(), desc=\"Processing images\"):\n",
    "        gts, dets = get_image_annotations(coco_gt, coco_dt, img_id, max_dets)\n",
    "        all_gts.extend(gts)\n",
    "        all_dets.extend(dets)\n",
    "    \n",
    "    return all_gts, all_dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.78s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "predictions_json = \"\"   # Path to the predictions JSON file\n",
    "ground_truth_json = \"\"  # Path to the val annotations JSON file\n",
    "\n",
    "coco_gt = COCO(ground_truth_json)       # Load ground truth annotations\n",
    "coco_dt = coco_gt.loadRes(predictions_json) # Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 5000/5000 [00:01<00:00, 3699.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36781, 279003, 70734)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts, dets = prepare_inputs(coco_gt, coco_dt, max_dets=100)\n",
    "len(gts), len(dets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your task: implement code to compute the Expected Calibration Error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Compute TIDE statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: size-based analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Code: Spatial Grid data structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Grid Implementation\n",
    "\n",
    "The `SpatialGrid` class implements a spatial indexing data structure that helps efficiently find nearby objects. Using this data structure is useful for our size-based analysis as it significantly reduces the time complexity of finding overlapping boxes.\n",
    "\n",
    "### How it works:\n",
    "1. The image space is divided into a grid of cells. The size of the cells is defined by the `cell_size` parameter.\n",
    "2. Each bounding box is mapped to the cells it overlaps.\n",
    "3. When searching for nearby objects, we only need to check objects in the relevant grid cells.\n",
    "\n",
    "### Usage Example:\n",
    "```python\n",
    "grid = SpatialGrid(cell_size=100)\n",
    "grid.add_box(0, [100, 100, 200, 200])  # Add a box with index 0, and bbox coordinates [100, 100, 200, 200]\n",
    "nearby = grid.get_nearby_indices([150, 150, 250, 250])  # Find boxes near the bbox [150, 150, 250, 250]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialGrid:\n",
    "    def __init__(self, cell_size: int = 100):\n",
    "        \"\"\"A spatial indexing structure for efficient nearby object queries.\n",
    "        \n",
    "        This data structure divides 2D space into a grid and maintains a mapping of\n",
    "        which objects overlap with each grid cell, enabling efficient spatial queries.\n",
    "        \"\"\"\n",
    "        self.cell_size: int = cell_size\n",
    "        # self.grid = defaultdict(list)\n",
    "        self.grid: Dict[Tuple[int, int], List[int]] = defaultdict(list)\n",
    "    \n",
    "    def get_cell_coords(self, bbox: np.ndarray) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"Get all grid cells that a bounding box overlaps with.\n",
    "        \n",
    "        Args:\n",
    "            bbox: Bounding box coordinates [x1, y1, x2, y2]\n",
    "                where (x1, y1) is the top-left corner and (x2, y2) is the bottom-right corner\n",
    "\n",
    "        Returns:\n",
    "            Set of (x, y) grid cell coordinates\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        start_x = int(x1 // self.cell_size)\n",
    "        end_x = int(x2 // self.cell_size)\n",
    "        start_y = int(y1 // self.cell_size)\n",
    "        end_y = int(y2 // self.cell_size)\n",
    "        return {(i, j) for i in range(start_x, end_x + 1) \n",
    "                       for j in range(start_y, end_y + 1)}\n",
    "    \n",
    "    def add_box(self, idx: int, bbox: np.ndarray):\n",
    "        \"\"\"Add a bounding box to the spatial grid.\n",
    "        \n",
    "        Args:\n",
    "            idx: Index of the bounding box\n",
    "            bbox: Bounding box coordinates [x1, y1, x2, y2]\n",
    "        \"\"\"\n",
    "        cells = self.get_cell_coords(bbox)\n",
    "        for cell in cells:\n",
    "            self.grid[cell].append(idx)\n",
    "    \n",
    "    def get_nearby_indices(self, bbox: np.ndarray) -> Set[int]:\n",
    "        \"\"\"Get indices of bounding boxes that are near the given bounding box.\n",
    "        \n",
    "        Args:\n",
    "            bbox: Bounding box coordinates [x1, y1, x2, y2]\n",
    "            \n",
    "        Returns:\n",
    "            Set of indices of nearby bounding boxes\n",
    "        \"\"\"\n",
    "        cells = self.get_cell_coords(bbox)\n",
    "        nearby = set()\n",
    "        for cell in cells:\n",
    "            nearby.update(self.grid[cell])\n",
    "        return nearby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size thresholds as per COCO\n",
    "SMALL_THRESH = 32 * 32\n",
    "MEDIUM_THRESH = 96 * 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your task: Implement the size-based ECE computation.\n",
    "\n",
    "## Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size-based TIDE computation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
